{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9646c7",
   "metadata": {},
   "source": [
    "# Pandas ðŸ¼ (panel data => data over multiple time periods)\n",
    "Powerful tool for data analysis.\n",
    "Helps to work with tabular data.\n",
    "**Why do we use Pandas?**\n",
    "1. Used for analyzing, cleaning, exploring, and manipulating data.\n",
    "2. Pandas allows us to analyze big data and make conclusions.\n",
    "3. It is an important library in data science to get insights from data.  \n",
    "<img src=\"images/pd_df.png\" width=300 height=200/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae15623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d210daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57da0168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "pd.read_csv(\n",
      "    filepath_or_buffer: \u001b[33m'FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]'\u001b[39m,\n",
      "    *,\n",
      "    sep: \u001b[33m'str | None | lib.NoDefault'\u001b[39m = <no_default>,\n",
      "    delimiter: \u001b[33m'str | None | lib.NoDefault'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    header: \u001b[33m\"int | Sequence[int] | None | Literal['infer']\"\u001b[39m = \u001b[33m'infer'\u001b[39m,\n",
      "    names: \u001b[33m'Sequence[Hashable] | None | lib.NoDefault'\u001b[39m = <no_default>,\n",
      "    index_col: \u001b[33m'IndexLabel | Literal[False] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    usecols: \u001b[33m'UsecolsArgType'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    dtype: \u001b[33m'DtypeArg | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    engine: \u001b[33m'CSVEngine | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    converters: \u001b[33m'Mapping[Hashable, Callable] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    true_values: \u001b[33m'list | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    false_values: \u001b[33m'list | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    skipinitialspace: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    skiprows: \u001b[33m'list[int] | int | Callable[[Hashable], bool] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    skipfooter: \u001b[33m'int'\u001b[39m = \u001b[32m0\u001b[39m,\n",
      "    nrows: \u001b[33m'int | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    na_values: \u001b[33m'Hashable | Iterable[Hashable] | Mapping[Hashable, Iterable[Hashable]] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    keep_default_na: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    na_filter: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    verbose: \u001b[33m'bool | lib.NoDefault'\u001b[39m = <no_default>,\n",
      "    skip_blank_lines: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    parse_dates: \u001b[33m'bool | Sequence[Hashable] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    infer_datetime_format: \u001b[33m'bool | lib.NoDefault'\u001b[39m = <no_default>,\n",
      "    keep_date_col: \u001b[33m'bool | lib.NoDefault'\u001b[39m = <no_default>,\n",
      "    date_parser: \u001b[33m'Callable | lib.NoDefault'\u001b[39m = <no_default>,\n",
      "    date_format: \u001b[33m'str | dict[Hashable, str] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    dayfirst: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    cache_dates: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    iterator: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    chunksize: \u001b[33m'int | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    compression: \u001b[33m'CompressionOptions'\u001b[39m = \u001b[33m'infer'\u001b[39m,\n",
      "    thousands: \u001b[33m'str | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    decimal: \u001b[33m'str'\u001b[39m = \u001b[33m'.'\u001b[39m,\n",
      "    lineterminator: \u001b[33m'str | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    quotechar: \u001b[33m'str'\u001b[39m = \u001b[33m'\"'\u001b[39m,\n",
      "    quoting: \u001b[33m'int'\u001b[39m = \u001b[32m0\u001b[39m,\n",
      "    doublequote: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    escapechar: \u001b[33m'str | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    comment: \u001b[33m'str | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    encoding: \u001b[33m'str | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    encoding_errors: \u001b[33m'str | None'\u001b[39m = \u001b[33m'strict'\u001b[39m,\n",
      "    dialect: \u001b[33m'str | csv.Dialect | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    on_bad_lines: \u001b[33m'str'\u001b[39m = \u001b[33m'error'\u001b[39m,\n",
      "    delim_whitespace: \u001b[33m'bool | lib.NoDefault'\u001b[39m = <no_default>,\n",
      "    low_memory: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    memory_map: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    float_precision: \u001b[33m\"Literal['high', 'legacy'] | None\"\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    storage_options: \u001b[33m'StorageOptions | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    dtype_backend: \u001b[33m'DtypeBackend | lib.NoDefault'\u001b[39m = <no_default>,\n",
      ") -> \u001b[33m'DataFrame | TextFileReader'\u001b[39m\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Read a comma-separated values (csv) file into DataFrame.\n",
      "\n",
      "Also supports optionally iterating or breaking of the file\n",
      "into chunks.\n",
      "\n",
      "Additional help can be found in the online docs for\n",
      "`IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "filepath_or_buffer : str, path object or file-like object\n",
      "    Any valid string path is acceptable. The string could be a URL. Valid\n",
      "    URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
      "    expected. A local file could be: file://localhost/path/to/table.csv.\n",
      "\n",
      "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "\n",
      "    By file-like object, we refer to objects with a ``read()`` method, such as\n",
      "    a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
      "sep : str, default ','\n",
      "    Character or regex pattern to treat as the delimiter. If ``sep=None``, the\n",
      "    C engine cannot automatically detect\n",
      "    the separator, but the Python parsing engine can, meaning the latter will\n",
      "    be used and automatically detect the separator from only the first valid\n",
      "    row of the file by Python's builtin sniffer tool, ``csv.Sniffer``.\n",
      "    In addition, separators longer than 1 character and different from\n",
      "    ``'\\s+'`` will be interpreted as regular expressions and will also force\n",
      "    the use of the Python parsing engine. Note that regex delimiters are prone\n",
      "    to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
      "delimiter : str, optional\n",
      "    Alias for ``sep``.\n",
      "header : int, Sequence of int, 'infer' or None, default 'infer'\n",
      "    Row number(s) containing column labels and marking the start of the\n",
      "    data (zero-indexed). Default behavior is to infer the column names: if no ``names``\n",
      "    are passed the behavior is identical to ``header=0`` and column\n",
      "    names are inferred from the first line of the file, if column\n",
      "    names are passed explicitly to ``names`` then the behavior is identical to\n",
      "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "    replace existing names. The header can be a list of integers that\n",
      "    specify row locations for a :class:`~pandas.MultiIndex` on the columns\n",
      "    e.g. ``[0, 1, 3]``. Intervening rows that are not specified will be\n",
      "    skipped (e.g. 2 in this example is skipped). Note that this\n",
      "    parameter ignores commented lines and empty lines if\n",
      "    ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
      "    data rather than the first line of the file.\n",
      "names : Sequence of Hashable, optional\n",
      "    Sequence of column labels to apply. If the file contains a header row,\n",
      "    then you should explicitly pass ``header=0`` to override the column names.\n",
      "    Duplicates in this list are not allowed.\n",
      "index_col : Hashable, Sequence of Hashable or False, optional\n",
      "  Column(s) to use as row label(s), denoted either by column labels or column\n",
      "  indices.  If a sequence of labels or indices is given, :class:`~pandas.MultiIndex`\n",
      "  will be formed for the row labels.\n",
      "\n",
      "  Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
      "  column as the index, e.g., when you have a malformed file with delimiters at\n",
      "  the end of each line.\n",
      "usecols : Sequence of Hashable or Callable, optional\n",
      "    Subset of columns to select, denoted either by column labels or column indices.\n",
      "    If list-like, all elements must either\n",
      "    be positional (i.e. integer indices into the document columns) or strings\n",
      "    that correspond to column names provided either by the user in ``names`` or\n",
      "    inferred from the document header row(s). If ``names`` are given, the document\n",
      "    header row(s) are not taken into account. For example, a valid list-like\n",
      "    ``usecols`` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
      "    Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "    To instantiate a :class:`~pandas.DataFrame` from ``data`` with element order\n",
      "    preserved use ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]``\n",
      "    for columns in ``['foo', 'bar']`` order or\n",
      "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "    for ``['bar', 'foo']`` order.\n",
      "\n",
      "    If callable, the callable function will be evaluated against the column\n",
      "    names, returning names where the callable function evaluates to ``True``. An\n",
      "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "    parsing time and lower memory usage.\n",
      "dtype : dtype or dict of {Hashable : dtype}, optional\n",
      "    Data type(s) to apply to either the whole dataset or individual columns.\n",
      "    E.g., ``{'a': np.float64, 'b': np.int32, 'c': 'Int64'}``\n",
      "    Use ``str`` or ``object`` together with suitable ``na_values`` settings\n",
      "    to preserve and not interpret ``dtype``.\n",
      "    If ``converters`` are specified, they will be applied INSTEAD\n",
      "    of ``dtype`` conversion.\n",
      "\n",
      "    .. versionadded:: 1.5.0\n",
      "\n",
      "        Support for ``defaultdict`` was added. Specify a ``defaultdict`` as input where\n",
      "        the default determines the ``dtype`` of the columns which are not explicitly\n",
      "        listed.\n",
      "engine : {'c', 'python', 'pyarrow'}, optional\n",
      "    Parser engine to use. The C and pyarrow engines are faster, while the python engine\n",
      "    is currently more feature-complete. Multithreading is currently only supported by\n",
      "    the pyarrow engine.\n",
      "\n",
      "    .. versionadded:: 1.4.0\n",
      "\n",
      "        The 'pyarrow' engine was added as an *experimental* engine, and some features\n",
      "        are unsupported, or may not work correctly, with this engine.\n",
      "converters : dict of {Hashable : Callable}, optional\n",
      "    Functions for converting values in specified columns. Keys can either\n",
      "    be column labels or column indices.\n",
      "true_values : list, optional\n",
      "    Values to consider as ``True`` in addition to case-insensitive variants of 'True'.\n",
      "false_values : list, optional\n",
      "    Values to consider as ``False`` in addition to case-insensitive variants of 'False'.\n",
      "skipinitialspace : bool, default False\n",
      "    Skip spaces after delimiter.\n",
      "skiprows : int, list of int or Callable, optional\n",
      "    Line numbers to skip (0-indexed) or number of lines to skip (``int``)\n",
      "    at the start of the file.\n",
      "\n",
      "    If callable, the callable function will be evaluated against the row\n",
      "    indices, returning ``True`` if the row should be skipped and ``False`` otherwise.\n",
      "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "skipfooter : int, default 0\n",
      "    Number of lines at bottom of file to skip (Unsupported with ``engine='c'``).\n",
      "nrows : int, optional\n",
      "    Number of rows of file to read. Useful for reading pieces of large files.\n",
      "na_values : Hashable, Iterable of Hashable or dict of {Hashable : Iterable}, optional\n",
      "    Additional strings to recognize as ``NA``/``NaN``. If ``dict`` passed, specific\n",
      "    per-column ``NA`` values.  By default the following values are interpreted as\n",
      "    ``NaN``: \" \", \"#N/A\", \"#N/A N/A\", \"#NA\", \"-1.#IND\", \"-1.#QNAN\", \"-NaN\", \"-nan\",\n",
      "    \"1.#IND\", \"1.#QNAN\", \"<NA>\", \"N/A\", \"NA\", \"NULL\", \"NaN\", \"None\",\n",
      "    \"n/a\", \"nan\", \"null \".\n",
      "\n",
      "keep_default_na : bool, default True\n",
      "    Whether or not to include the default ``NaN`` values when parsing the data.\n",
      "    Depending on whether ``na_values`` is passed in, the behavior is as follows:\n",
      "\n",
      "    * If ``keep_default_na`` is ``True``, and ``na_values`` are specified, ``na_values``\n",
      "      is appended to the default ``NaN`` values used for parsing.\n",
      "    * If ``keep_default_na`` is ``True``, and ``na_values`` are not specified, only\n",
      "      the default ``NaN`` values are used for parsing.\n",
      "    * If ``keep_default_na`` is ``False``, and ``na_values`` are specified, only\n",
      "      the ``NaN`` values specified ``na_values`` are used for parsing.\n",
      "    * If ``keep_default_na`` is ``False``, and ``na_values`` are not specified, no\n",
      "      strings will be parsed as ``NaN``.\n",
      "\n",
      "    Note that if ``na_filter`` is passed in as ``False``, the ``keep_default_na`` and\n",
      "    ``na_values`` parameters will be ignored.\n",
      "na_filter : bool, default True\n",
      "    Detect missing value markers (empty strings and the value of ``na_values``). In\n",
      "    data without any ``NA`` values, passing ``na_filter=False`` can improve the\n",
      "    performance of reading a large file.\n",
      "verbose : bool, default False\n",
      "    Indicate number of ``NA`` values placed in non-numeric columns.\n",
      "\n",
      "    .. deprecated:: 2.2.0\n",
      "skip_blank_lines : bool, default True\n",
      "    If ``True``, skip over blank lines rather than interpreting as ``NaN`` values.\n",
      "parse_dates : bool, list of Hashable, list of lists or dict of {Hashable : list}, default False\n",
      "    The behavior is as follows:\n",
      "\n",
      "    * ``bool``. If ``True`` -> try parsing the index. Note: Automatically set to\n",
      "      ``True`` if ``date_format`` or ``date_parser`` arguments have been passed.\n",
      "    * ``list`` of ``int`` or names. e.g. If ``[1, 2, 3]`` -> try parsing columns 1, 2, 3\n",
      "      each as a separate date column.\n",
      "    * ``list`` of ``list``. e.g.  If ``[[1, 3]]`` -> combine columns 1 and 3 and parse\n",
      "      as a single date column. Values are joined with a space before parsing.\n",
      "    * ``dict``, e.g. ``{'foo' : [1, 3]}`` -> parse columns 1, 3 as date and call\n",
      "      result 'foo'. Values are joined with a space before parsing.\n",
      "\n",
      "    If a column or index cannot be represented as an array of ``datetime``,\n",
      "    say because of an unparsable value or a mixture of timezones, the column\n",
      "    or index will be returned unaltered as an ``object`` data type. For\n",
      "    non-standard ``datetime`` parsing, use :func:`~pandas.to_datetime` after\n",
      "    :func:`~pandas.read_csv`.\n",
      "\n",
      "    Note: A fast-path exists for iso8601-formatted dates.\n",
      "infer_datetime_format : bool, default False\n",
      "    If ``True`` and ``parse_dates`` is enabled, pandas will attempt to infer the\n",
      "    format of the ``datetime`` strings in the columns, and if it can be inferred,\n",
      "    switch to a faster method of parsing them. In some cases this can increase\n",
      "    the parsing speed by 5-10x.\n",
      "\n",
      "    .. deprecated:: 2.0.0\n",
      "        A strict version of this argument is now the default, passing it has no effect.\n",
      "\n",
      "keep_date_col : bool, default False\n",
      "    If ``True`` and ``parse_dates`` specifies combining multiple columns then\n",
      "    keep the original columns.\n",
      "date_parser : Callable, optional\n",
      "    Function to use for converting a sequence of string columns to an array of\n",
      "    ``datetime`` instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "    conversion. pandas will try to call ``date_parser`` in three different ways,\n",
      "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "    (as defined by ``parse_dates``) as arguments; 2) concatenate (row-wise) the\n",
      "    string values from the columns defined by ``parse_dates`` into a single array\n",
      "    and pass that; and 3) call ``date_parser`` once for each row using one or\n",
      "    more strings (corresponding to the columns defined by ``parse_dates``) as\n",
      "    arguments.\n",
      "\n",
      "    .. deprecated:: 2.0.0\n",
      "       Use ``date_format`` instead, or read in as ``object`` and then apply\n",
      "       :func:`~pandas.to_datetime` as-needed.\n",
      "date_format : str or dict of column -> format, optional\n",
      "    Format to use for parsing dates when used in conjunction with ``parse_dates``.\n",
      "    The strftime to parse time, e.g. :const:`\"%d/%m/%Y\"`. See\n",
      "    `strftime documentation\n",
      "    <https://docs.python.org/3/library/datetime.html\n",
      "    #strftime-and-strptime-behavior>`_ for more information on choices, though\n",
      "    note that :const:`\"%f\"` will parse all the way up to nanoseconds.\n",
      "    You can also pass:\n",
      "\n",
      "    - \"ISO8601\", to parse any `ISO8601 <https://en.wikipedia.org/wiki/ISO_8601>`_\n",
      "        time string (not necessarily in exactly the same format);\n",
      "    - \"mixed\", to infer the format for each element individually. This is risky,\n",
      "        and you should probably use it along with `dayfirst`.\n",
      "\n",
      "    .. versionadded:: 2.0.0\n",
      "dayfirst : bool, default False\n",
      "    DD/MM format dates, international and European format.\n",
      "cache_dates : bool, default True\n",
      "    If ``True``, use a cache of unique, converted dates to apply the ``datetime``\n",
      "    conversion. May produce significant speed-up when parsing duplicate\n",
      "    date strings, especially ones with timezone offsets.\n",
      "\n",
      "iterator : bool, default False\n",
      "    Return ``TextFileReader`` object for iteration or getting chunks with\n",
      "    ``get_chunk()``.\n",
      "chunksize : int, optional\n",
      "    Number of lines to read from the file per chunk. Passing a value will cause the\n",
      "    function to return a ``TextFileReader`` object for iteration.\n",
      "    See the `IO Tools docs\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "    for more information on ``iterator`` and ``chunksize``.\n",
      "\n",
      "compression : str or dict, default 'infer'\n",
      "    For on-the-fly decompression of on-disk data. If 'infer' and 'filepath_or_buffer' is\n",
      "    path-like, then detect compression from the following extensions: '.gz',\n",
      "    '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "    (otherwise no compression).\n",
      "    If using 'zip' or 'tar', the ZIP file must contain only one data file to be read in.\n",
      "    Set to ``None`` for no decompression.\n",
      "    Can also be a dict with key ``'method'`` set\n",
      "    to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      "    other key-value pairs are forwarded to\n",
      "    ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "    ``bz2.BZ2File``, ``zstandard.ZstdDecompressor``, ``lzma.LZMAFile`` or\n",
      "    ``tarfile.TarFile``, respectively.\n",
      "    As an example, the following could be passed for Zstandard decompression using a\n",
      "    custom compression dictionary:\n",
      "    ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
      "\n",
      "    .. versionadded:: 1.5.0\n",
      "        Added support for `.tar` files.\n",
      "\n",
      "    .. versionchanged:: 1.4.0 Zstandard support.\n",
      "\n",
      "thousands : str (length 1), optional\n",
      "    Character acting as the thousands separator in numerical values.\n",
      "decimal : str (length 1), default '.'\n",
      "    Character to recognize as decimal point (e.g., use ',' for European data).\n",
      "lineterminator : str (length 1), optional\n",
      "    Character used to denote a line break. Only valid with C parser.\n",
      "quotechar : str (length 1), optional\n",
      "    Character used to denote the start and end of a quoted item. Quoted\n",
      "    items can include the ``delimiter`` and it will be ignored.\n",
      "quoting : {0 or csv.QUOTE_MINIMAL, 1 or csv.QUOTE_ALL, 2 or csv.QUOTE_NONNUMERIC, 3 or csv.QUOTE_NONE}, default csv.QUOTE_MINIMAL\n",
      "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Default is\n",
      "    ``csv.QUOTE_MINIMAL`` (i.e., 0) which implies that only fields containing special\n",
      "    characters are quoted (e.g., characters defined in ``quotechar``, ``delimiter``,\n",
      "    or ``lineterminator``.\n",
      "doublequote : bool, default True\n",
      "   When ``quotechar`` is specified and ``quoting`` is not ``QUOTE_NONE``, indicate\n",
      "   whether or not to interpret two consecutive ``quotechar`` elements INSIDE a\n",
      "   field as a single ``quotechar`` element.\n",
      "escapechar : str (length 1), optional\n",
      "    Character used to escape other characters.\n",
      "comment : str (length 1), optional\n",
      "    Character indicating that the remainder of line should not be parsed.\n",
      "    If found at the beginning\n",
      "    of a line, the line will be ignored altogether. This parameter must be a\n",
      "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "    fully commented lines are ignored by the parameter ``header`` but not by\n",
      "    ``skiprows``. For example, if ``comment='#'``, parsing\n",
      "    ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in ``'a,b,c'`` being\n",
      "    treated as the header.\n",
      "encoding : str, optional, default 'utf-8'\n",
      "    Encoding to use for UTF when reading/writing (ex. ``'utf-8'``). `List of Python\n",
      "    standard encodings\n",
      "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
      "\n",
      "encoding_errors : str, optional, default 'strict'\n",
      "    How encoding errors are treated. `List of possible values\n",
      "    <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
      "\n",
      "    .. versionadded:: 1.3.0\n",
      "\n",
      "dialect : str or csv.Dialect, optional\n",
      "    If provided, this parameter will override values (default or not) for the\n",
      "    following parameters: ``delimiter``, ``doublequote``, ``escapechar``,\n",
      "    ``skipinitialspace``, ``quotechar``, and ``quoting``. If it is necessary to\n",
      "    override values, a ``ParserWarning`` will be issued. See ``csv.Dialect``\n",
      "    documentation for more details.\n",
      "on_bad_lines : {'error', 'warn', 'skip'} or Callable, default 'error'\n",
      "    Specifies what to do upon encountering a bad line (a line with too many fields).\n",
      "    Allowed values are :\n",
      "\n",
      "    - ``'error'``, raise an Exception when a bad line is encountered.\n",
      "    - ``'warn'``, raise a warning when a bad line is encountered and skip that line.\n",
      "    - ``'skip'``, skip bad lines without raising or warning when they are encountered.\n",
      "\n",
      "    .. versionadded:: 1.3.0\n",
      "\n",
      "    .. versionadded:: 1.4.0\n",
      "\n",
      "        - Callable, function with signature\n",
      "          ``(bad_line: list[str]) -> list[str] | None`` that will process a single\n",
      "          bad line. ``bad_line`` is a list of strings split by the ``sep``.\n",
      "          If the function returns ``None``, the bad line will be ignored.\n",
      "          If the function returns a new ``list`` of strings with more elements than\n",
      "          expected, a ``ParserWarning`` will be emitted while dropping extra elements.\n",
      "          Only supported when ``engine='python'``\n",
      "\n",
      "    .. versionchanged:: 2.2.0\n",
      "\n",
      "        - Callable, function with signature\n",
      "          as described in `pyarrow documentation\n",
      "          <https://arrow.apache.org/docs/python/generated/pyarrow.csv.ParseOptions.html\n",
      "          #pyarrow.csv.ParseOptions.invalid_row_handler>`_ when ``engine='pyarrow'``\n",
      "\n",
      "delim_whitespace : bool, default False\n",
      "    Specifies whether or not whitespace (e.g. ``' '`` or ``'\\t'``) will be\n",
      "    used as the ``sep`` delimiter. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "    is set to ``True``, nothing should be passed in for the ``delimiter``\n",
      "    parameter.\n",
      "\n",
      "    .. deprecated:: 2.2.0\n",
      "        Use ``sep=\"\\s+\"`` instead.\n",
      "low_memory : bool, default True\n",
      "    Internally process the file in chunks, resulting in lower memory use\n",
      "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "    types either set ``False``, or specify the type with the ``dtype`` parameter.\n",
      "    Note that the entire file is read into a single :class:`~pandas.DataFrame`\n",
      "    regardless, use the ``chunksize`` or ``iterator`` parameter to return the data in\n",
      "    chunks. (Only valid with C parser).\n",
      "memory_map : bool, default False\n",
      "    If a filepath is provided for ``filepath_or_buffer``, map the file object\n",
      "    directly onto memory and access the data directly from there. Using this\n",
      "    option can improve performance because there is no longer any I/O overhead.\n",
      "float_precision : {'high', 'legacy', 'round_trip'}, optional\n",
      "    Specifies which converter the C engine should use for floating-point\n",
      "    values. The options are ``None`` or ``'high'`` for the ordinary converter,\n",
      "    ``'legacy'`` for the original lower precision pandas converter, and\n",
      "    ``'round_trip'`` for the round-trip converter.\n",
      "\n",
      "storage_options : dict, optional\n",
      "    Extra options that make sense for a particular storage connection, e.g.\n",
      "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "    are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "    URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "    forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "    details, and for more examples on storage options refer `here\n",
      "    <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "    highlight=storage_options#reading-writing-remote-files>`_.\n",
      "\n",
      "dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
      "    Back-end data type applied to the resultant :class:`DataFrame`\n",
      "    (still experimental). Behaviour is as follows:\n",
      "\n",
      "    * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
      "      (default).\n",
      "    * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
      "      DataFrame.\n",
      "\n",
      "    .. versionadded:: 2.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "DataFrame or TextFileReader\n",
      "    A comma-separated values (csv) file is returned as two-dimensional\n",
      "    data structure with labeled axes.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "read_table : Read general delimited file into DataFrame.\n",
      "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
      "\u001b[31mFile:\u001b[39m      ~/Learn/Repos/MyRepos/ai_ml_knowhow/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "# documentation\n",
    "pd.read_csv?\n",
    "#dir(pd)\n",
    "#help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "084643b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print(pd.options.display.width)\n",
    "pd.set_option('display.width', 300)\n",
    "print(pd.options.display.max_rows)\n",
    "#pd.describe_option()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57a17f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year    City      Sport     Discipline        Athlete Name  NOC Gender  Event Event Gender   Medal  Position\n",
      "0  1896  Athens    Cycling  Cycling Track       FLAMENG, LÃ©on  FRA    Men  100km            M    Gold         1\n",
      "1  1896  Athens    Cycling  Cycling Track  KOLETTIS, Georgios  GRE    Men  100km            M  Silver         2\n",
      "2  1896  Athens  Athletics      Athletics       LANE, Francis  USA    Men   100m            M  Bronze         3\n",
      "3  1896  Athens  Athletics      Athletics    SZOKOLYI, Alajos  HUN    Men   100m            M  Bronze         3\n",
      "4  1896  Athens  Athletics      Athletics       BURKE, Thomas  USA    Men   100m            M    Gold         1\n",
      "******************************************************************************************\n",
      "     booking_id  lead_time market_segment_type  no_of_special_requests  avg_price_per_room  no_of_adults  no_of_weekend_nights arrival_date  required_car_parking_space  no_of_week_nights booking_status rebooked\n",
      "0  INNHG_101034          0              Online                       0               85.03             1                     1   2021-01-01                           0                  0   Not Canceled      NaN\n",
      "1  INNHG_101035         34              Online                       2              125.10             2                     2   2021-01-01                           0                  0   Not Canceled      NaN\n",
      "2  INNHG_101036         24              Online                       1               71.69             2                     2   2021-01-01                           0                  0   Not Canceled      NaN\n",
      "3  INNHG_101037         23              Online                       0               84.70             1                     2   2021-01-01                           0                  0   Not Canceled      NaN\n",
      "4  INNHG_101038         46              Online                       1              149.40             2                     2   2021-01-01                           0                  3       Canceled       No\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "if Path('./data/olympics_1896_2004.csv').exists():\n",
    "    odf = pd.read_csv(filepath_or_buffer='./data/olympics_1896_2004.csv', skiprows=5)\n",
    "    print(odf.head())\n",
    "print(\"***\"*30)\n",
    "if Path('./data/INNHotelsGroup_pastdata.csv').exists():\n",
    "    hdf = pd.read_csv(filepath_or_buffer='./data/INNHotelsGroup_pastdata.csv')\n",
    "    print(hdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f26b909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27174, 11)\n",
      "******************************************************************************************\n",
      "Index(['Year', 'City', 'Sport', 'Discipline', 'Athlete Name', 'NOC', 'Gender', 'Event', 'Event Gender', 'Medal', 'Position'], dtype='object')\n",
      "******************************************************************************************\n",
      "       Year    City       Sport    Discipline        Athlete Name  NOC Gender            Event Event Gender   Medal  Position\n",
      "27012  2004  Athens  Volleyball    Volleyball     GARCIA, Ricardo  BRA    Men       volleyball            M    Gold         1\n",
      "16436  1980  Moscow     Cycling  Cycling Road  KONECNY, Vlastibor  TCH    Men  team time trial            M  Bronze         3\n",
      "******************************************************************************************\n",
      "Output of describe function - \n",
      "                Year      Position\n",
      "count  27174.000000  27174.000000\n",
      "mean    1964.685803      1.992566\n",
      "std       31.590396      0.817469\n",
      "min     1896.000000      1.000000\n",
      "25%     1936.000000      1.000000\n",
      "50%     1972.000000      2.000000\n",
      "75%     1992.000000      3.000000\n",
      "max     2004.000000      3.000000\n",
      "******************************************************************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27174 entries, 0 to 27173\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Year          27174 non-null  int64 \n",
      " 1   City          27174 non-null  object\n",
      " 2   Sport         27174 non-null  object\n",
      " 3   Discipline    27174 non-null  object\n",
      " 4   Athlete Name  27174 non-null  object\n",
      " 5   NOC           27174 non-null  object\n",
      " 6   Gender        27174 non-null  object\n",
      " 7   Event         27174 non-null  object\n",
      " 8   Event Gender  27174 non-null  object\n",
      " 9   Medal         27174 non-null  object\n",
      " 10  Position      27174 non-null  int64 \n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 2.3+ MB\n",
      "Output of info function - \n",
      " None\n",
      "******************************************************************************************\n",
      "Output of dtype attribute - \n",
      " Year             int64\n",
      "City            object\n",
      "Sport           object\n",
      "Discipline      object\n",
      "Athlete Name    object\n",
      "NOC             object\n",
      "Gender          object\n",
      "Event           object\n",
      "Event Gender    object\n",
      "Medal           object\n",
      "Position         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(odf.shape)\n",
    "print(\"***\"*30)\n",
    "print(odf.columns)\n",
    "print(\"***\"*30)\n",
    "print(odf.sample(2))\n",
    "print(\"***\"*30)\n",
    "print(\"Output of describe function - \\n\",odf.describe())\n",
    "print(\"***\"*30)\n",
    "print(\"Output of info function - \\n\", odf.info())\n",
    "print(\"***\"*30)\n",
    "print(\"Output of dtype attribute - \\n\", odf.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30741435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27093, 12)\n",
      "******************************************************************************************\n",
      "Index(['booking_id', 'lead_time', 'market_segment_type', 'no_of_special_requests', 'avg_price_per_room', 'no_of_adults', 'no_of_weekend_nights', 'arrival_date', 'required_car_parking_space', 'no_of_week_nights', 'booking_status', 'rebooked'], dtype='object')\n",
      "******************************************************************************************\n",
      "         booking_id  lead_time market_segment_type  no_of_special_requests  avg_price_per_room  no_of_adults  no_of_weekend_nights arrival_date  required_car_parking_space  no_of_week_nights booking_status rebooked\n",
      "17591  INNHG_118625          6             Offline                       1                85.0             2                     1   2022-03-20                           0                  0   Not Canceled      NaN\n",
      "761    INNHG_101795        292             Offline                       0                90.0             1                     0   2021-01-21                           0                  2   Not Canceled      NaN\n",
      "******************************************************************************************\n",
      "          lead_time  no_of_special_requests  avg_price_per_room  no_of_adults  no_of_weekend_nights  required_car_parking_space  no_of_week_nights\n",
      "count  27093.000000            27093.000000        27093.000000  27093.000000          27093.000000                27093.000000       27093.000000\n",
      "mean      81.605249                0.556454          101.025910      1.825822              0.778319                    0.028864           2.171373\n",
      "std       84.901428                0.743715           34.557289      0.512182              0.861787                    0.167426           1.386023\n",
      "min        0.000000                0.000000            0.000000      0.000000              0.000000                    0.000000           0.000000\n",
      "25%       14.000000                0.000000           79.000000      2.000000              0.000000                    0.000000           1.000000\n",
      "50%       55.000000                0.000000           97.000000      2.000000              1.000000                    0.000000           2.000000\n",
      "75%      118.000000                1.000000          119.000000      2.000000              1.000000                    0.000000           3.000000\n",
      "max      443.000000                5.000000          540.000000      4.000000              6.000000                    1.000000          17.000000\n",
      "******************************************************************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27093 entries, 0 to 27092\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   booking_id                  27093 non-null  object \n",
      " 1   lead_time                   27093 non-null  int64  \n",
      " 2   market_segment_type         27093 non-null  object \n",
      " 3   no_of_special_requests      27093 non-null  int64  \n",
      " 4   avg_price_per_room          27093 non-null  float64\n",
      " 5   no_of_adults                27093 non-null  int64  \n",
      " 6   no_of_weekend_nights        27093 non-null  int64  \n",
      " 7   arrival_date                27093 non-null  object \n",
      " 8   required_car_parking_space  27093 non-null  int64  \n",
      " 9   no_of_week_nights           27093 non-null  int64  \n",
      " 10  booking_status              27093 non-null  object \n",
      " 11  rebooked                    8857 non-null   object \n",
      "dtypes: float64(1), int64(6), object(5)\n",
      "memory usage: 2.5+ MB\n",
      "None\n",
      "******************************************************************************************\n",
      "booking_id                     object\n",
      "lead_time                       int64\n",
      "market_segment_type            object\n",
      "no_of_special_requests          int64\n",
      "avg_price_per_room            float64\n",
      "no_of_adults                    int64\n",
      "no_of_weekend_nights            int64\n",
      "arrival_date                   object\n",
      "required_car_parking_space      int64\n",
      "no_of_week_nights               int64\n",
      "booking_status                 object\n",
      "rebooked                       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(hdf.shape)\n",
    "print(\"***\"*30)\n",
    "print(hdf.columns)\n",
    "print(\"***\"*30)\n",
    "print(hdf.sample(2))\n",
    "print(\"***\"*30)\n",
    "print(hdf.describe())\n",
    "print(\"***\"*30)\n",
    "print(hdf.info())\n",
    "print(\"***\"*30)\n",
    "print(hdf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18adf8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m   pd.get_option(*args, **kwds) -> \u001b[33m'T'\u001b[39m\n",
      "\u001b[31mType:\u001b[39m        CallableDynamicDoc\n",
      "\u001b[31mString form:\u001b[39m <pandas._config.config.CallableDynamicDoc object at 0x105c734d0>\n",
      "\u001b[31mFile:\u001b[39m        ~/Learn/Repos/MyRepos/ai_ml_knowhow/.venv/lib/python3.12/site-packages/pandas/_config/config.py\n",
      "\u001b[31mDocstring:\u001b[39m  \n",
      "get_option(pat)\n",
      "\n",
      "Retrieves the value of the specified option.\n",
      "\n",
      "Available options:\n",
      "\n",
      "- compute.[use_bottleneck, use_numba, use_numexpr]\n",
      "- display.[chop_threshold, colheader_justify, date_dayfirst, date_yearfirst,\n",
      "  encoding, expand_frame_repr, float_format]\n",
      "- display.html.[border, table_schema, use_mathjax]\n",
      "- display.[large_repr, max_categories, max_columns, max_colwidth, max_dir_items,\n",
      "  max_info_columns, max_info_rows, max_rows, max_seq_items, memory_usage,\n",
      "  min_rows, multi_sparse, notebook_repr_html, pprint_nest_depth, precision,\n",
      "  show_dimensions]\n",
      "- display.unicode.[ambiguous_as_wide, east_asian_width]\n",
      "- display.[width]\n",
      "- future.[infer_string, no_silent_downcasting]\n",
      "- io.excel.ods.[reader, writer]\n",
      "- io.excel.xls.[reader]\n",
      "- io.excel.xlsb.[reader]\n",
      "- io.excel.xlsm.[reader, writer]\n",
      "- io.excel.xlsx.[reader, writer]\n",
      "- io.hdf.[default_format, dropna_table]\n",
      "- io.parquet.[engine]\n",
      "- io.sql.[engine]\n",
      "- mode.[chained_assignment, copy_on_write, data_manager, sim_interactive,\n",
      "  string_storage, use_inf_as_na]\n",
      "- plotting.[backend]\n",
      "- plotting.matplotlib.[register_converters]\n",
      "- styler.format.[decimal, escape, formatter, na_rep, precision, thousands]\n",
      "- styler.html.[mathjax]\n",
      "- styler.latex.[environment, hrules, multicol_align, multirow_align]\n",
      "- styler.render.[encoding, max_columns, max_elements, max_rows, repr]\n",
      "- styler.sparse.[columns, index]\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "pat : str\n",
      "    Regexp which should match a single option.\n",
      "    Note: partial matches are supported for convenience, but unless you use the\n",
      "    full option name (e.g. x.y.z.option_name), your code may break in future\n",
      "    versions if new options with similar names are introduced.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "result : the value of the option\n",
      "\n",
      "Raises\n",
      "------\n",
      "OptionError : if no such option exists\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Please reference the :ref:`User Guide <options>` for more information.\n",
      "\n",
      "The available options with its descriptions:\n",
      "\n",
      "compute.use_bottleneck : bool\n",
      "    Use the bottleneck library to accelerate if it is installed,\n",
      "    the default is True\n",
      "    Valid values: False,True\n",
      "    [default: True] [currently: True]\n",
      "compute.use_numba : bool\n",
      "    Use the numba engine option for select operations if it is installed,\n",
      "    the default is False\n",
      "    Valid values: False,True\n",
      "    [default: False] [currently: False]\n",
      "compute.use_numexpr : bool\n",
      "    Use the numexpr library to accelerate computation if it is installed,\n",
      "    the default is True\n",
      "    Valid values: False,True\n",
      "    [default: True] [currently: True]\n",
      "display.chop_threshold : float or None\n",
      "    if set to a float value, all float values smaller than the given threshold\n",
      "    will be displayed as exactly 0 by repr and friends.\n",
      "    [default: None] [currently: None]\n",
      "display.colheader_justify : 'left'/'right'\n",
      "    Controls the justification of column headers. used by DataFrameFormatter.\n",
      "    [default: right] [currently: right]\n",
      "display.date_dayfirst : boolean\n",
      "    When True, prints and parses dates with the day first, eg 20/01/2005\n",
      "    [default: False] [currently: False]\n",
      "display.date_yearfirst : boolean\n",
      "    When True, prints and parses dates with the year first, eg 2005/01/20\n",
      "    [default: False] [currently: False]\n",
      "display.encoding : str/unicode\n",
      "    Defaults to the detected encoding of the console.\n",
      "    Specifies the encoding to be used for strings returned by to_string,\n",
      "    these are generally strings meant to be displayed on the console.\n",
      "    [default: UTF-8] [currently: UTF-8]\n",
      "display.expand_frame_repr : boolean\n",
      "    Whether to print out the full DataFrame repr for wide DataFrames across\n",
      "    multiple lines, `max_columns` is still respected, but the output will\n",
      "    wrap-around across multiple \"pages\" if its width exceeds `display.width`.\n",
      "    [default: True] [currently: True]\n",
      "display.float_format : callable\n",
      "    The callable should accept a floating point number and return\n",
      "    a string with the desired format of the number. This is used\n",
      "    in some places like SeriesFormatter.\n",
      "    See formats.format.EngFormatter for an example.\n",
      "    [default: None] [currently: None]\n",
      "display.html.border : int\n",
      "    A ``border=value`` attribute is inserted in the ``<table>`` tag\n",
      "    for the DataFrame HTML repr.\n",
      "    [default: 1] [currently: 1]\n",
      "display.html.table_schema : boolean\n",
      "    Whether to publish a Table Schema representation for frontends\n",
      "    that support it.\n",
      "    (default: False)\n",
      "    [default: False] [currently: False]\n",
      "display.html.use_mathjax : boolean\n",
      "    When True, Jupyter notebook will process table contents using MathJax,\n",
      "    rendering mathematical expressions enclosed by the dollar symbol.\n",
      "    (default: True)\n",
      "    [default: True] [currently: True]\n",
      "display.large_repr : 'truncate'/'info'\n",
      "    For DataFrames exceeding max_rows/max_cols, the repr (and HTML repr) can\n",
      "    show a truncated table, or switch to the view from\n",
      "    df.info() (the behaviour in earlier versions of pandas).\n",
      "    [default: truncate] [currently: truncate]\n",
      "display.max_categories : int\n",
      "    This sets the maximum number of categories pandas should output when\n",
      "    printing out a `Categorical` or a Series of dtype \"category\".\n",
      "    [default: 8] [currently: 8]\n",
      "display.max_columns : int\n",
      "    If max_cols is exceeded, switch to truncate view. Depending on\n",
      "    `large_repr`, objects are either centrally truncated or printed as\n",
      "    a summary view. 'None' value means unlimited.\n",
      "\n",
      "    In case python/IPython is running in a terminal and `large_repr`\n",
      "    equals 'truncate' this can be set to 0 or None and pandas will auto-detect\n",
      "    the width of the terminal and print a truncated object which fits\n",
      "    the screen width. The IPython notebook, IPython qtconsole, or IDLE\n",
      "    do not run in a terminal and hence it is not possible to do\n",
      "    correct auto-detection and defaults to 20.\n",
      "    [default: 20] [currently: 20]\n",
      "display.max_colwidth : int or None\n",
      "    The maximum width in characters of a column in the repr of\n",
      "    a pandas data structure. When the column overflows, a \"...\"\n",
      "    placeholder is embedded in the output. A 'None' value means unlimited.\n",
      "    [default: 50] [currently: 100]\n",
      "display.max_dir_items : int\n",
      "    The number of items that will be added to `dir(...)`. 'None' value means\n",
      "    unlimited. Because dir is cached, changing this option will not immediately\n",
      "    affect already existing dataframes until a column is deleted or added.\n",
      "\n",
      "    This is for instance used to suggest columns from a dataframe to tab\n",
      "    completion.\n",
      "    [default: 100] [currently: 100]\n",
      "display.max_info_columns : int\n",
      "    max_info_columns is used in DataFrame.info method to decide if\n",
      "    per column information will be printed.\n",
      "    [default: 100] [currently: 100]\n",
      "display.max_info_rows : int\n",
      "    df.info() will usually show null-counts for each column.\n",
      "    For large frames this can be quite slow. max_info_rows and max_info_cols\n",
      "    limit this null check only to frames with smaller dimensions than\n",
      "    specified.\n",
      "    [default: 1690785] [currently: 1690785]\n",
      "display.max_rows : int\n",
      "    If max_rows is exceeded, switch to truncate view. Depending on\n",
      "    `large_repr`, objects are either centrally truncated or printed as\n",
      "    a summary view. 'None' value means unlimited.\n",
      "\n",
      "    In case python/IPython is running in a terminal and `large_repr`\n",
      "    equals 'truncate' this can be set to 0 and pandas will auto-detect\n",
      "    the height of the terminal and print a truncated object which fits\n",
      "    the screen height. The IPython notebook, IPython qtconsole, or\n",
      "    IDLE do not run in a terminal and hence it is not possible to do\n",
      "    correct auto-detection.\n",
      "    [default: 60] [currently: 60]\n",
      "display.max_seq_items : int or None\n",
      "    When pretty-printing a long sequence, no more then `max_seq_items`\n",
      "    will be printed. If items are omitted, they will be denoted by the\n",
      "    addition of \"...\" to the resulting string.\n",
      "\n",
      "    If set to None, the number of items to be printed is unlimited.\n",
      "    [default: 100] [currently: 100]\n",
      "display.memory_usage : bool, string or None\n",
      "    This specifies if the memory usage of a DataFrame should be displayed when\n",
      "    df.info() is called. Valid values True,False,'deep'\n",
      "    [default: True] [currently: True]\n",
      "display.min_rows : int\n",
      "    The numbers of rows to show in a truncated view (when `max_rows` is\n",
      "    exceeded). Ignored when `max_rows` is set to None or 0. When set to\n",
      "    None, follows the value of `max_rows`.\n",
      "    [default: 10] [currently: 10]\n",
      "display.multi_sparse : boolean\n",
      "    \"sparsify\" MultiIndex display (don't display repeated\n",
      "    elements in outer levels within groups)\n",
      "    [default: True] [currently: True]\n",
      "display.notebook_repr_html : boolean\n",
      "    When True, IPython notebook will use html representation for\n",
      "    pandas objects (if it is available).\n",
      "    [default: True] [currently: True]\n",
      "display.pprint_nest_depth : int\n",
      "    Controls the number of nested levels to process when pretty-printing\n",
      "    [default: 3] [currently: 3]\n",
      "display.precision : int\n",
      "    Floating point output precision in terms of number of places after the\n",
      "    decimal, for regular formatting as well as scientific notation. Similar\n",
      "    to ``precision`` in :meth:`numpy.set_printoptions`.\n",
      "    [default: 6] [currently: 6]\n",
      "display.show_dimensions : boolean or 'truncate'\n",
      "    Whether to print out dimensions at the end of DataFrame repr.\n",
      "    If 'truncate' is specified, only print out the dimensions if the\n",
      "    frame is truncated (e.g. not display all rows and/or columns)\n",
      "    [default: truncate] [currently: truncate]\n",
      "display.unicode.ambiguous_as_wide : boolean\n",
      "    Whether to use the Unicode East Asian Width to calculate the display text\n",
      "    width.\n",
      "    Enabling this may affect to the performance (default: False)\n",
      "    [default: False] [currently: False]\n",
      "display.unicode.east_asian_width : boolean\n",
      "    Whether to use the Unicode East Asian Width to calculate the display text\n",
      "    width.\n",
      "    Enabling this may affect to the performance (default: False)\n",
      "    [default: False] [currently: False]\n",
      "display.width : int\n",
      "    Width of the display in characters. In case python/IPython is running in\n",
      "    a terminal this can be set to None and pandas will correctly auto-detect\n",
      "    the width.\n",
      "    Note that the IPython notebook, IPython qtconsole, or IDLE do not run in a\n",
      "    terminal and hence it is not possible to correctly detect the width.\n",
      "    [default: 80] [currently: 300]\n",
      "future.infer_string Whether to infer sequence of str objects as pyarrow string dtype, which will be the default in pandas 3.0 (at which point this option will be deprecated).\n",
      "    [default: False] [currently: False]\n",
      "future.no_silent_downcasting Whether to opt-in to the future behavior which will *not* silently downcast results from Series and DataFrame `where`, `mask`, and `clip` methods. Silent downcasting will be removed in pandas 3.0 (at which point this option will be deprecated).\n",
      "    [default: False] [currently: False]\n",
      "io.excel.ods.reader : string\n",
      "    The default Excel reader engine for 'ods' files. Available options:\n",
      "    auto, odf, calamine.\n",
      "    [default: auto] [currently: auto]\n",
      "io.excel.ods.writer : string\n",
      "    The default Excel writer engine for 'ods' files. Available options:\n",
      "    auto, odf.\n",
      "    [default: auto] [currently: auto]\n",
      "io.excel.xls.reader : string\n",
      "    The default Excel reader engine for 'xls' files. Available options:\n",
      "    auto, xlrd, calamine.\n",
      "    [default: auto] [currently: auto]\n",
      "io.excel.xlsb.reader : string\n",
      "    The default Excel reader engine for 'xlsb' files. Available options:\n",
      "    auto, pyxlsb, calamine.\n",
      "    [default: auto] [currently: auto]\n",
      "io.excel.xlsm.reader : string\n",
      "    The default Excel reader engine for 'xlsm' files. Available options:\n",
      "    auto, xlrd, openpyxl, calamine.\n",
      "    [default: auto] [currently: auto]\n",
      "io.excel.xlsm.writer : string\n",
      "    The default Excel writer engine for 'xlsm' files. Available options:\n",
      "    auto, openpyxl.\n",
      "    [default: auto] [currently: auto]\n",
      "io.excel.xlsx.reader : string\n",
      "    The default Excel reader engine for 'xlsx' files. Available options:\n",
      "    auto, xlrd, openpyxl, calamine.\n",
      "    [default: auto] [currently: auto]\n",
      "io.excel.xlsx.writer : string\n",
      "    The default Excel writer engine for 'xlsx' files. Available options:\n",
      "    auto, openpyxl, xlsxwriter.\n",
      "    [default: auto] [currently: auto]\n",
      "io.hdf.default_format : format\n",
      "    default format writing format, if None, then\n",
      "    put will default to 'fixed' and append will default to 'table'\n",
      "    [default: None] [currently: None]\n",
      "io.hdf.dropna_table : boolean\n",
      "    drop ALL nan rows when appending to a table\n",
      "    [default: False] [currently: False]\n",
      "io.parquet.engine : string\n",
      "    The default parquet reader/writer engine. Available options:\n",
      "    'auto', 'pyarrow', 'fastparquet', the default is 'auto'\n",
      "    [default: auto] [currently: auto]\n",
      "io.sql.engine : string\n",
      "    The default sql reader/writer engine. Available options:\n",
      "    'auto', 'sqlalchemy', the default is 'auto'\n",
      "    [default: auto] [currently: auto]\n",
      "mode.chained_assignment : string\n",
      "    Raise an exception, warn, or no action if trying to use chained assignment,\n",
      "    The default is warn\n",
      "    [default: warn] [currently: warn]\n",
      "mode.copy_on_write : bool\n",
      "    Use new copy-view behaviour using Copy-on-Write. Defaults to False,\n",
      "    unless overridden by the 'PANDAS_COPY_ON_WRITE' environment variable\n",
      "    (if set to \"1\" for True, needs to be set before pandas is imported).\n",
      "    [default: False] [currently: False]\n",
      "mode.data_manager : string\n",
      "    Internal data manager type; can be \"block\" or \"array\". Defaults to \"block\",\n",
      "    unless overridden by the 'PANDAS_DATA_MANAGER' environment variable (needs\n",
      "    to be set before pandas is imported).\n",
      "    [default: block] [currently: block]\n",
      "    (Deprecated, use `` instead.)\n",
      "mode.sim_interactive : boolean\n",
      "    Whether to simulate interactive mode for purposes of testing\n",
      "    [default: False] [currently: False]\n",
      "mode.string_storage : string\n",
      "    The default storage for StringDtype. This option is ignored if\n",
      "    ``future.infer_string`` is set to True.\n",
      "    [default: python] [currently: python]\n",
      "mode.use_inf_as_na : boolean\n",
      "    True means treat None, NaN, INF, -INF as NA (old way),\n",
      "    False means None and NaN are null, but INF, -INF are not NA\n",
      "    (new way).\n",
      "\n",
      "    This option is deprecated in pandas 2.1.0 and will be removed in 3.0.\n",
      "    [default: False] [currently: False]\n",
      "    (Deprecated, use `` instead.)\n",
      "plotting.backend : str\n",
      "    The plotting backend to use. The default value is \"matplotlib\", the\n",
      "    backend provided with pandas. Other backends can be specified by\n",
      "    providing the name of the module that implements the backend.\n",
      "    [default: matplotlib] [currently: matplotlib]\n",
      "plotting.matplotlib.register_converters : bool or 'auto'.\n",
      "    Whether to register converters with matplotlib's units registry for\n",
      "    dates, times, datetimes, and Periods. Toggling to False will remove\n",
      "    the converters, restoring any converters that pandas overwrote.\n",
      "    [default: auto] [currently: auto]\n",
      "styler.format.decimal : str\n",
      "    The character representation for the decimal separator for floats and complex.\n",
      "    [default: .] [currently: .]\n",
      "styler.format.escape : str, optional\n",
      "    Whether to escape certain characters according to the given context; html or latex.\n",
      "    [default: None] [currently: None]\n",
      "styler.format.formatter : str, callable, dict, optional\n",
      "    A formatter object to be used as default within ``Styler.format``.\n",
      "    [default: None] [currently: None]\n",
      "styler.format.na_rep : str, optional\n",
      "    The string representation for values identified as missing.\n",
      "    [default: None] [currently: None]\n",
      "styler.format.precision : int\n",
      "    The precision for floats and complex numbers.\n",
      "    [default: 6] [currently: 6]\n",
      "styler.format.thousands : str, optional\n",
      "    The character representation for thousands separator for floats, int and complex.\n",
      "    [default: None] [currently: None]\n",
      "styler.html.mathjax : bool\n",
      "    If False will render special CSS classes to table attributes that indicate Mathjax\n",
      "    will not be used in Jupyter Notebook.\n",
      "    [default: True] [currently: True]\n",
      "styler.latex.environment : str\n",
      "    The environment to replace ``\\begin{table}``. If \"longtable\" is used results\n",
      "    in a specific longtable environment format.\n",
      "    [default: None] [currently: None]\n",
      "styler.latex.hrules : bool\n",
      "    Whether to add horizontal rules on top and bottom and below the headers.\n",
      "    [default: False] [currently: False]\n",
      "styler.latex.multicol_align : {\"r\", \"c\", \"l\", \"naive-l\", \"naive-r\"}\n",
      "    The specifier for horizontal alignment of sparsified LaTeX multicolumns. Pipe\n",
      "    decorators can also be added to non-naive values to draw vertical\n",
      "    rules, e.g. \"\\|r\" will draw a rule on the left side of right aligned merged cells.\n",
      "    [default: r] [currently: r]\n",
      "styler.latex.multirow_align : {\"c\", \"t\", \"b\"}\n",
      "    The specifier for vertical alignment of sparsified LaTeX multirows.\n",
      "    [default: c] [currently: c]\n",
      "styler.render.encoding : str\n",
      "    The encoding used for output HTML and LaTeX files.\n",
      "    [default: utf-8] [currently: utf-8]\n",
      "styler.render.max_columns : int, optional\n",
      "    The maximum number of columns that will be rendered. May still be reduced to\n",
      "    satisfy ``max_elements``, which takes precedence.\n",
      "    [default: None] [currently: None]\n",
      "styler.render.max_elements : int\n",
      "    The maximum number of data-cell (<td>) elements that will be rendered before\n",
      "    trimming will occur over columns, rows or both if needed.\n",
      "    [default: 262144] [currently: 262144]\n",
      "styler.render.max_rows : int, optional\n",
      "    The maximum number of rows that will be rendered. May still be reduced to\n",
      "    satisfy ``max_elements``, which takes precedence.\n",
      "    [default: None] [currently: None]\n",
      "styler.render.repr : str\n",
      "    Determine which output to use in Jupyter Notebook in {\"html\", \"latex\"}.\n",
      "    [default: html] [currently: html]\n",
      "styler.sparse.columns : bool\n",
      "    Whether to sparsify the display of hierarchical columns. Setting to False will\n",
      "    display each explicit level element in a hierarchical key for each column.\n",
      "    [default: True] [currently: True]\n",
      "styler.sparse.index : bool\n",
      "    Whether to sparsify the display of a hierarchical index. Setting to False will\n",
      "    display each explicit level element in a hierarchical key for each row.\n",
      "    [default: True] [currently: True]\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> pd.get_option('display.max_columns')  # doctest: +SKIP\n",
      "4"
     ]
    }
   ],
   "source": [
    "pd.get_option?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e3b43c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Discipline</th>\n",
       "      <th>Athlete Name</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Event</th>\n",
       "      <th>Event Gender</th>\n",
       "      <th>Medal</th>\n",
       "      <th>Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21963</th>\n",
       "      <td>1996</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Cycling</td>\n",
       "      <td>Cycling Track</td>\n",
       "      <td>WOODS, Dean</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Men</td>\n",
       "      <td>Team Pursuit (4000m)</td>\n",
       "      <td>M</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23178</th>\n",
       "      <td>2000</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Taekwondo</td>\n",
       "      <td>Taekwondo</td>\n",
       "      <td>GENTIL, Pascal</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Men</td>\n",
       "      <td>+ 80 kg</td>\n",
       "      <td>M</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24431</th>\n",
       "      <td>2000</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Handball</td>\n",
       "      <td>Handball</td>\n",
       "      <td>LINDGREN, Ola</td>\n",
       "      <td>SWE</td>\n",
       "      <td>Men</td>\n",
       "      <td>handball</td>\n",
       "      <td>M</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17431</th>\n",
       "      <td>1984</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Rowing</td>\n",
       "      <td>Rowing</td>\n",
       "      <td>NIELSEN, Lars</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Men</td>\n",
       "      <td>four without coxswain (4-)</td>\n",
       "      <td>M</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1900</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Rugby</td>\n",
       "      <td>Rugby</td>\n",
       "      <td>LANDVOIGT, Arnold</td>\n",
       "      <td>GER</td>\n",
       "      <td>Men</td>\n",
       "      <td>rugby</td>\n",
       "      <td>M</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year         City      Sport     Discipline       Athlete Name  NOC Gender                       Event Event Gender   Medal  Position\n",
       "21963  1996      Atlanta    Cycling  Cycling Track        WOODS, Dean  AUS    Men        Team Pursuit (4000m)            M  Bronze         3\n",
       "23178  2000       Sydney  Taekwondo      Taekwondo     GENTIL, Pascal  FRA    Men                     + 80 kg            M  Bronze         3\n",
       "24431  2000       Sydney   Handball       Handball      LINDGREN, Ola  SWE    Men                    handball            M  Silver         2\n",
       "17431  1984  Los Angeles     Rowing         Rowing      NIELSEN, Lars  DEN    Men  four without coxswain (4-)            M  Bronze         3\n",
       "557    1900        Paris      Rugby          Rugby  LANDVOIGT, Arnold  GER    Men                       rugby            M  Silver         2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pd.get_option('display.width'))\n",
    "pd.set_option('display.width', 1000)\n",
    "odf.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f2f6045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             FLAMENG, LÃ©on\n",
      "1        KOLETTIS, Georgios\n",
      "2             LANE, Francis\n",
      "3          SZOKOLYI, Alajos\n",
      "4             BURKE, Thomas\n",
      "                ...        \n",
      "27169    LOGOUNOVA, Tatiana\n",
      "27170         SIVKOVA, Anna\n",
      "27171        BOKEL, Claudia\n",
      "27172       DUPLITZER, Imke\n",
      "27173     HEIDEMANN, Britta\n",
      "Name: Athlete Name, Length: 27174, dtype: object\n",
      "******************************************************************************************\n",
      "<class 'pandas.core.series.Series'>\n",
      "******************************************************************************************\n",
      "0        Cycling Track\n",
      "1        Cycling Track\n",
      "2            Athletics\n",
      "3            Athletics\n",
      "4            Athletics\n",
      "             ...      \n",
      "27169          Fencing\n",
      "27170          Fencing\n",
      "27171          Fencing\n",
      "27172          Fencing\n",
      "27173          Fencing\n",
      "Name: Discipline, Length: 27174, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(odf['Athlete Name'])\n",
    "print(\"***\"*30)\n",
    "print(type(odf['Athlete Name']))\n",
    "print(\"***\"*30)\n",
    "# Series becomes attribute\n",
    "print(odf.Discipline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9882c4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1896 1900 1904 1908 1912 1920 1924 1928 1932 1936 1948 1952 1956 1960\n",
      " 1964 1968 1972 1976 1980 1984 1988 1992 1996 2000 2004] Year\n",
      "2000    2015\n",
      "2004    1998\n",
      "1996    1859\n",
      "1992    1705\n",
      "1988    1546\n",
      "1984    1459\n",
      "1980    1387\n",
      "1976    1305\n",
      "1920    1298\n",
      "1972    1185\n",
      "1968    1031\n",
      "1964    1010\n",
      "1952     889\n",
      "1956     885\n",
      "1912     885\n",
      "1924     884\n",
      "1960     882\n",
      "1936     875\n",
      "1948     814\n",
      "1908     804\n",
      "1928     710\n",
      "1932     615\n",
      "1900     512\n",
      "1904     470\n",
      "1896     151\n",
      "Name: count, dtype: int64\n",
      "******************************************************************************************\n",
      "['Cycling' 'Athletics' 'Aquatics' 'Shooting' 'Tennis' 'Fencing'\n",
      " 'Weightlifting' 'Gymnastics' 'Wrestling' 'Sailing' 'Archery'\n",
      " 'Basque Pelota' 'Cricket' 'Croquet' 'Rowing' 'Football' 'Equestrian'\n",
      " 'Golf' 'Polo' 'Rugby' 'Tug of War' 'Boxing' 'Roque' 'Lacrosse'\n",
      " 'Water Motorsports' 'Rackets' 'Hockey' 'Jeu de paume' 'Skating'\n",
      " 'Modern Pentathlon' 'Ice Hockey' 'Canoe / Kayak' 'Basketball' 'Handball'\n",
      " 'Judo' 'Volleyball' 'Table Tennis' 'Baseball' 'Badminton' 'Softball'\n",
      " 'Taekwondo' 'Triathlon'] Sport\n",
      "Aquatics             3481\n",
      "Athletics            3271\n",
      "Rowing               2379\n",
      "Gymnastics           2115\n",
      "Fencing              1485\n",
      "Football             1279\n",
      "Hockey               1227\n",
      "Wrestling            1069\n",
      "Shooting             1060\n",
      "Sailing              1007\n",
      "Cycling               954\n",
      "Canoe / Kayak         918\n",
      "Basketball            868\n",
      "Equestrian            849\n",
      "Volleyball            826\n",
      "Handball              801\n",
      "Boxing                798\n",
      "Weightlifting         503\n",
      "Judo                  379\n",
      "Archery               281\n",
      "Baseball              263\n",
      "Tennis                254\n",
      "Rugby                 192\n",
      "Modern Pentathlon     168\n",
      "Softball              135\n",
      "Badminton              96\n",
      "Table Tennis           96\n",
      "Tug of War             94\n",
      "Polo                   66\n",
      "Lacrosse               59\n",
      "Taekwondo              48\n",
      "Golf                   30\n",
      "Ice Hockey             27\n",
      "Skating                27\n",
      "Cricket                24\n",
      "Triathlon              12\n",
      "Rackets                10\n",
      "Croquet                 8\n",
      "Water Motorsports       5\n",
      "Basque Pelota           4\n",
      "Jeu de paume            3\n",
      "Roque                   3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(odf['Year'].unique(), odf['Year'].value_counts())\n",
    "print(\"***\"*30)\n",
    "print(odf['Sport'].unique(), odf['Sport'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f7b45b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time range covered = [1896 1900 1904 1908 1912 1920 1924 1928 1932 1936 1948 1952 1956 1960\n",
      " 1964 1968 1972 1976 1980 1984 1988 1992 1996 2000 2004]\n",
      "They span 1896 to 2004\n"
     ]
    }
   ],
   "source": [
    "# What is the time range covered in this dataset?\n",
    "print(f\"Time range covered = {odf['Year'].unique()}\")\n",
    "print(f\"They span {int(odf['Year'].min())} to {int(odf['Year'].max())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52f9b1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types of medals awarded = ['Gold' 'Silver' 'Bronze']\n"
     ]
    }
   ],
   "source": [
    "# What are the types of medals awarded?\n",
    "print(f\"Types of medals awarded = {odf['Medal'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8dbb413b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gold' 'Silver' 'Bronze'] Medal\n",
      "Gold      9181\n",
      "Silver    9014\n",
      "Bronze    8979\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Across all of the Olympic Games, how many gold, silver, and bronze medals have there been?\n",
    "print(odf['Medal'].unique(), odf['Medal'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06bf60c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FRA', 'GRE', 'USA', 'HUN', 'GER', 'AUT', 'GBR', 'AUS', 'DEN',\n",
       "       'ZZX', 'SUI', 'IND', 'NED', 'CAN', 'NOR', 'BEL', 'ESP', 'BOH',\n",
       "       'ITA', 'SWE', 'CUB', 'RU1', 'FIN', 'RSA', 'ANZ', 'LUX', 'EST',\n",
       "       'BRA', 'JPN', 'TCH', 'NZL', 'ARG', 'HAI', 'POL', 'URU', 'YUG',\n",
       "       'ROU', 'POR', 'EGY', 'PHI', 'IRL', 'CHI', 'MEX', 'LAT', 'TUR',\n",
       "       'KOR', 'PAN', 'JAM', 'SRI', 'PER', 'PUR', 'IRI', 'TRI', 'URS',\n",
       "       'LIB', 'BUL', 'VEN', 'EUA', 'PAK', 'ISL', 'BAH', 'BWI', 'GHA',\n",
       "       'IRQ', 'SIN', 'TPE', 'ETH', 'MAR', 'TUN', 'NGR', 'KEN', 'FRG',\n",
       "       'MGL', 'GDR', 'UGA', 'CMR', 'PRK', 'COL', 'NIG', 'BER', 'THA',\n",
       "       'TAN', 'GUY', 'ZIM', 'ZAM', 'CHN', 'CIV', 'DOM', 'ALG', 'SYR',\n",
       "       'SUR', 'CRC', 'SEN', 'AHO', 'DJI', 'ISV', 'INA', 'EUN', 'NAM',\n",
       "       'IOP', 'QAT', 'ISR', 'LTU', 'CRO', 'SLO', 'MAS', 'RUS', 'UKR',\n",
       "       'TGA', 'ARM', 'BLR', 'MDA', 'ECU', 'KAZ', 'AZE', 'BDI', 'SVK',\n",
       "       'CZE', 'UZB', 'GEO', 'MOZ', 'HKG', 'KGZ', 'BAR', 'KSA', 'VIE',\n",
       "       'MKD', 'KUW', 'ERI', 'SCG', 'UAE', 'PAR'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the different National Olympic Committees (NOCs)?\n",
    "odf.NOC.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4eda6ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year    City      Sport     Discipline        Athlete_Name  NOC Gender  Event Event_Gender   Medal  Position\n",
      "0  1896  Athens    Cycling  Cycling Track       FLAMENG, LÃ©on  FRA    Men  100km            M    Gold         1\n",
      "1  1896  Athens    Cycling  Cycling Track  KOLETTIS, Georgios  GRE    Men  100km            M  Silver         2\n",
      "2  1896  Athens  Athletics      Athletics       LANE, Francis  USA    Men   100m            M  Bronze         3\n"
     ]
    }
   ],
   "source": [
    "## Rename\n",
    "odf.rename(columns={'Athlete Name': 'Athlete_Name', 'Event Gender': 'Event_Gender'})\n",
    "print(odf.head(3))\n",
    "# Few other ways of changing column names. Usage of header=0 in read-csv() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e54f78f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year       City          Sport       Discipline          Athlete_Name  NOC Gender                     Event Event_Gender   Medal  Position\n",
      "10413  1960       Rome         Hockey           Hockey   ROIG JUNYENT, Pedro  ESP    Men                    hockey            M  Bronze         3\n",
      "12830  1972     Munich       Aquatics         Swimming           SPITZ, Mark  USA    Men            200m butterfly            M    Gold         1\n",
      "2857   1920    Antwerp       Aquatics         Swimming  KEALOHA, Warren Paoa  USA    Men           100m backstroke            M    Gold         1\n",
      "23809  2000     Sydney  Canoe / Kayak  Canoe / Kayak F         MERKOV, Petar  BUL    Men  K-1 1000m (kayak single)            M  Silver         2\n",
      "19914  1992  Barcelona      Athletics        Athletics           IMOH, Chidi  NGR    Men              4x100m relay            M  Silver         2\n",
      "******************************************************************************************\n",
      "Index(['Year', 'City', 'Sport', 'Discipline', 'Athlete_Name', 'NOC', 'Gender', 'Event', 'Event_Gender', 'Medal', 'Position'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(odf.sample(5))\n",
    "print(\"***\"*30)\n",
    "print(odf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12d9e760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year     City       Sport   Discipline                      Athlete_Name  NOC Gender              Event Event_Gender   Medal  Position\n",
      "6857   1936   Berlin    Handball     Handball                   BANDHOLZ, Willi  GER    Men           handball            M    Gold         1\n",
      "25969  2004   Athens    Baseball     Baseball       GOURRIEL CASTILLO, Yulieski  CUB    Men           baseball            M    Gold         1\n",
      "10547  1960     Rome  Equestrian      Jumping               CHAPOT, Frank Davis  USA    Men               team            X  Silver         2\n",
      "4033   1920  Antwerp  Gymnastics  Artistic G.  STEFFENSEN, Wilhelm Marius Bakke  NOR    Men  team, free system            M  Silver         2\n",
      "24891  2000   Sydney  Equestrian     Dressage                    WERTH, Isabell  GER  Women               team            X    Gold         1\n",
      "******************************************************************************************\n",
      "   Year    City      Sport     Discipline        Athlete_Name  NOC Gender  Event Event_Gender   Medal\n",
      "0  1896  Athens    Cycling  Cycling Track       FLAMENG, LÃ©on  FRA    Men  100km            M    Gold\n",
      "1  1896  Athens    Cycling  Cycling Track  KOLETTIS, Georgios  GRE    Men  100km            M  Silver\n",
      "2  1896  Athens  Athletics      Athletics       LANE, Francis  USA    Men   100m            M  Bronze\n",
      "3  1896  Athens  Athletics      Athletics    SZOKOLYI, Alajos  HUN    Men   100m            M  Bronze\n",
      "4  1896  Athens  Athletics      Athletics       BURKE, Thomas  USA    Men   100m            M    Gold\n",
      "******************************************************************************************\n",
      "       Year    City      Sport     Discipline        Athlete_Name  NOC Gender      Event Event_Gender   Medal  Position\n",
      "1      1896  Athens    Cycling  Cycling Track  KOLETTIS, Georgios  GRE    Men      100km            M  Silver         2\n",
      "2      1896  Athens  Athletics      Athletics       LANE, Francis  USA    Men       100m            M  Bronze         3\n",
      "3      1896  Athens  Athletics      Athletics    SZOKOLYI, Alajos  HUN    Men       100m            M  Bronze         3\n",
      "4      1896  Athens  Athletics      Athletics       BURKE, Thomas  USA    Men       100m            M    Gold         1\n",
      "5      1896  Athens  Athletics      Athletics      HOFMANN, Fritz  GER    Men       100m            M  Silver         2\n",
      "...     ...     ...        ...            ...                 ...  ...    ...        ...          ...     ...       ...\n",
      "27169  2004  Athens    Fencing        Fencing  LOGOUNOVA, Tatiana  RUS  Women  Ã©pÃ©e team            W    Gold         1\n",
      "27170  2004  Athens    Fencing        Fencing       SIVKOVA, Anna  RUS  Women  Ã©pÃ©e team            W    Gold         1\n",
      "27171  2004  Athens    Fencing        Fencing      BOKEL, Claudia  GER  Women  Ã©pÃ©e team            W  Silver         2\n",
      "27172  2004  Athens    Fencing        Fencing     DUPLITZER, Imke  GER  Women  Ã©pÃ©e team            W  Silver         2\n",
      "27173  2004  Athens    Fencing        Fencing   HEIDEMANN, Britta  GER  Women  Ã©pÃ©e team            W  Silver         2\n",
      "\n",
      "[27173 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop a series/column => coming from Database world\n",
    "print(odf.sample(5))\n",
    "print(\"***\"*30)\n",
    "print(odf.drop('Position', axis=1).head(5))\n",
    "print(\"***\"*30)\n",
    "print(odf.drop(0, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb849d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering rows. Operator => ==, !=, <, <=, >, >=, &, |, ~\n",
    "import pandas as pd\n",
    "\n",
    "if Path('./data/olympics_1896_2004.csv').exists():\n",
    "    odf = pd.read_csv(filepath_or_buffer='./data/olympics_1896_2004.csv', skiprows=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
